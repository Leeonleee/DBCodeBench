---
title: "reasoning.md"
author: "Leon Lee"
date: "2025-09-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pass@k comparison between reasoning models
## Claude
```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(scales)
library(stringr)

metric_family <- "unbiased"  # or "empirical"

# 2) Which models to include + in what ORDER
models_include <- c(
  "claude-sonnet-4_thinking0",
  "claude-sonnet-4_thinking8k",
  "claude-sonnet-4_thinking16k",
  "claude-sonnet-4_thinking24k"
)

# 3) Pretty labels for legend (only for the models you use)
model_names <- c(
  "gpt-5_reasoninglow"                = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"             = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"               = "GPT-5 (High Reasoning)",
  "o3"                                = "o3",
  "claude-sonnet-4_thinking0"         = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"        = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"       = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"       = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"                    = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"         = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium"      = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"        = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                       = "Qwen3 Coder",
  "kimi-k2-0905"                      = "Kimi K2 0905",
  "gpt-4o"                            = "GPT-4o"
)

# 4) Output paths
out_pdf <- sprintf("graphs/reasoning/reasoning_pass_at_k_%s_claude.pdf", metric_family)
out_tex <- sprintf("tables/reasoning/reasoning_pass_at_k_%s_claude.tex", metric_family)

# ==== Data ====
df <- read.csv("../analysis_results/all_models_summary.csv")

# Filter to the selected models (and keep their order)
df_sel <- df %>%
  filter(model %in% models_include) %>%
  mutate(model = factor(model, levels = models_include))

# Choose the metric columns by family
prefix <- if (metric_family == "unbiased") "unbiased_pass_at_" else "empirical_pass_at_"
metric_cols <- paste0(prefix, 1:5)

# Long form for plotting + table
long <- df_sel %>%
  select(model, all_of(metric_cols)) %>%
  pivot_longer(
    cols = all_of(metric_cols),
    names_to = "metric",
    values_to = "score"
  ) %>%
  mutate(
    k = as.integer(sub(".*_(\\d+)$", "\\1", metric)),
    model_label = recode(as.character(model), !!!model_names),
    # Keep legend order matching models_include (using pretty labels)
    model_label = factor(model_label, levels = recode(models_include, !!!model_names))
  )

# ==== Plot ====
p <- ggplot(long, aes(x = k, y = score, color = model_label, group = model_label)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = 1:5) +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  labs(
    title = if (metric_family == "unbiased") "Unbiased Pass@k by Model" else "Empirical Pass@k by Model",
    x = "k",
    y = "Pass@k (%)",
    color = "Model"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.title = element_text(),
    legend.text = element_text(),
    plot.title = element_text(face = "bold")
  )

p

# ==== Export Plot ====
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave(out_pdf, plot = p, width = 8, height = 4.5, device = "pdf")

# ==== LaTeX Table ====
library(knitr)
library(kableExtra)

# Wide table: rows = model_label, cols = k=1..5
tbl <- long %>%
  mutate(model_label = as.character(model_label)) %>%
  # Convert newline to LaTeX line break
  mutate(model_label = stringr::str_replace_all(model_label, "\n", "\\\\\n")) %>%
  mutate(k = paste0("k=", k)) %>%
  select(model_label, k, score) %>%
  pivot_wider(names_from = k, values_from = score) %>%
  # Keep original order of pretty labels
  mutate(model_label = factor(model_label, levels = stringr::str_replace_all(recode(models_include, !!!model_names), "\n", "\\\\\n"))) %>%
  arrange(model_label)

# Format as percentages (2 dp)
fmt_pct <- function(x) sprintf("%.2f\\%%", x * 100)
tbl_fmt <- tbl %>%
  mutate(across(starts_with("k="), fmt_pct))

if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)

caption_txt <- if (metric_family == "unbiased") {
  "Unbiased pass@k (\\%) by model."
} else {
  "Empirical pass@k (\\%) by model."
}

latex_tbl <- kable(
  tbl_fmt,
  format = "latex",
  booktabs = TRUE,
  caption = caption_txt,
  label = sprintf("tab:%s-passk-claude", metric_family),
  col.names = c("Model", paste0("k=", 1:5)),
  align = c("l", rep("c", 5)),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, out_tex)

```

## GPT-5

```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(scales)
library(stringr)

metric_family <- "unbiased"  # or "empirical"

# 2) Which models to include + in what ORDER
models_include <- c(
  "gpt-5_reasoninglow",
  "gpt-5_reasoningmedium",
  "gpt-5_reasoninghigh"
)

# 3) Pretty labels for legend (only for the models you use)
model_names <- c(
  "gpt-5_reasoninglow"                = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"             = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"               = "GPT-5 (High Reasoning)",
  "o3"                                = "o3",
  "claude-sonnet-4_thinking0"         = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"        = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"       = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"       = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"                    = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"         = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium"      = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"        = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                       = "Qwen3 Coder",
  "kimi-k2-0905"                      = "Kimi K2 0905",
  "gpt-4o"                            = "GPT-4o"
)

# 4) Output paths
out_pdf <- sprintf("graphs/reasoning/reasoning_pass_at_k_%s_gpt5.pdf", metric_family)
out_tex <- sprintf("tables/reasoning/reasoning_pass_at_k_%s_gpt5.tex", metric_family)

# ==== Data ====
df <- read.csv("../analysis_results/all_models_summary.csv")

# Filter to the selected models (and keep their order)
df_sel <- df %>%
  filter(model %in% models_include) %>%
  mutate(model = factor(model, levels = models_include))

# Choose the metric columns by family
prefix <- if (metric_family == "unbiased") "unbiased_pass_at_" else "empirical_pass_at_"
metric_cols <- paste0(prefix, 1:5)

# Long form for plotting + table
long <- df_sel %>%
  select(model, all_of(metric_cols)) %>%
  pivot_longer(
    cols = all_of(metric_cols),
    names_to = "metric",
    values_to = "score"
  ) %>%
  mutate(
    k = as.integer(sub(".*_(\\d+)$", "\\1", metric)),
    model_label = recode(as.character(model), !!!model_names),
    # Keep legend order matching models_include (using pretty labels)
    model_label = factor(model_label, levels = recode(models_include, !!!model_names))
  )

# ==== Plot ====
p <- ggplot(long, aes(x = k, y = score, color = model_label, group = model_label)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = 1:5) +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  labs(
    title = if (metric_family == "unbiased") "Unbiased Pass@k by Model" else "Empirical Pass@k by Model",
    x = "k",
    y = "Pass@k (%)",
    color = "Model"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    legend.title = element_text(),
    legend.text = element_text(),
    plot.title = element_text(face = "bold")
  )

p

# ==== Export Plot ====
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave(out_pdf, plot = p, width = 8, height = 4.5, device = "pdf")

# ==== LaTeX Table ====
library(knitr)
library(kableExtra)

# Wide table: rows = model_label, cols = k=1..5
tbl <- long %>%
  mutate(model_label = as.character(model_label)) %>%
  # Convert newline to LaTeX line break (not needed for GPT-5 labels, but safe)
  mutate(model_label = stringr::str_replace_all(model_label, "\n", "\\\\\n")) %>%
  mutate(k = paste0("k=", k)) %>%
  select(model_label, k, score) %>%
  tidyr::pivot_wider(names_from = k, values_from = score) %>%
  # Preserve order of pretty labels
  mutate(model_label = factor(model_label, levels = stringr::str_replace_all(recode(models_include, !!!model_names), "\n", "\\\\\n"))) %>%
  arrange(model_label)

# Format as percentages (2 dp)
fmt_pct <- function(x) sprintf("%.2f\\%%", x * 100)
tbl_fmt <- tbl %>%
  mutate(across(starts_with("k="), fmt_pct))

if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)

caption_txt <- if (metric_family == "unbiased") {
  "Unbiased pass@k (\\%) by model."
} else {
  "Empirical pass@k (\\%) by model."
}

latex_tbl <- kable(
  tbl_fmt,
  format = "latex",
  booktabs = TRUE,
  caption = caption_txt,
  label = sprintf("tab:%s-passk-gpt5", metric_family),
  col.names = c("Model", paste0("k=", 1:5)),
  align = c("l", rep("c", 5)),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, out_tex)

```

## gpt-oss-120b

```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(scales)
library(stringr)

metric_family <- "unbiased"  # or "empirical"

# 2) Which models to include + in what ORDER
models_include <- c(
  "gpt-oss-120b_reasoninglow",
  "gpt-oss-120b_reasoningmedium",
  "gpt-oss-120b_reasoninghigh"
)

# 3) Pretty labels for legend (only for the models you use)
model_names <- c(
  "gpt-5_reasoninglow"                = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"             = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"               = "GPT-5 (High Reasoning)",
  "o3"                                = "o3",
  "claude-sonnet-4_thinking0"         = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"        = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"       = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"       = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"                    = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"         = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium"      = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"        = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                       = "Qwen3 Coder",
  "kimi-k2-0905"                      = "Kimi K2 0905",
  "gpt-4o"                            = "GPT-4o"
)

# 4) Output paths
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)
out_pdf <- sprintf("graphs/reasoning/reasoning_pass_at_k_%s_oss.pdf", metric_family)
out_tex <- sprintf("tables/reasoning/reasoning_pass_at_k_%s_oss.tex", metric_family)

# ==== Data ====
df <- read.csv("../analysis_results/all_models_summary.csv")

# Filter to the selected models (and keep their order)
df_sel <- df %>%
  filter(model %in% models_include) %>%
  mutate(model = factor(model, levels = models_include))

# Choose the metric columns by family
prefix <- if (metric_family == "unbiased") "unbiased_pass_at_" else "empirical_pass_at_"
metric_cols <- paste0(prefix, 1:5)

# Long form for plotting + table
long <- df_sel %>%
  select(model, all_of(metric_cols)) %>%
  pivot_longer(
    cols = all_of(metric_cols),
    names_to = "metric",
    values_to = "score"
  ) %>%
  mutate(
    k = as.integer(sub(".*_(\\d+)$", "\\1", metric)),
    model_label = recode(as.character(model), !!!model_names),
    # Keep legend order matching models_include (using pretty labels)
    model_label = factor(model_label, levels = recode(models_include, !!!model_names))
  )

# ==== Plot ====
p <- ggplot(long, aes(x = k, y = score, color = model_label, group = model_label)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  scale_x_continuous(breaks = 1:5) +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  labs(
    title = if (metric_family == "unbiased") "Unbiased Pass@k by Model" else "Empirical Pass@k by Model",
    x = "k",
    y = "Pass@k (%)",
    color = "Model"
  ) +
  theme_bw() +
  theme(
    legend.position = "bottom",
    legend.title = element_text(),
    legend.text = element_text(),
    plot.title = element_text(face = "bold")
  )

p

# ==== Export Plot ====
ggsave(out_pdf, plot = p, width = 8, height = 4.5, device = "pdf")

# ==== LaTeX Table ====
library(knitr)
library(kableExtra)

# Wide table: rows = model_label, cols = k=1..5
tbl <- long %>%
  mutate(model_label = as.character(model_label)) %>%
  mutate(model_label = stringr::str_replace_all(model_label, "\n", "\\\\\n")) %>%
  mutate(k = paste0("k=", k)) %>%
  select(model_label, k, score) %>%
  tidyr::pivot_wider(names_from = k, values_from = score) %>%
  # Preserve pretty-label ordering
  mutate(model_label = factor(
    model_label,
    levels = stringr::str_replace_all(recode(models_include, !!!model_names), "\n", "\\\\\n")
  )) %>%
  arrange(model_label)

# Format as percentages (2 dp)
fmt_pct <- function(x) sprintf("%.2f\\%%", x * 100)
tbl_fmt <- tbl %>% mutate(across(starts_with("k="), fmt_pct))

caption_txt <- if (metric_family == "unbiased") {
  "Unbiased pass@k (\\%) by model."
} else {
  "Empirical pass@k (\\%) by model."
}

latex_tbl <- kable(
  tbl_fmt,
  format = "latex",
  booktabs = TRUE,
  caption = caption_txt,
  label = sprintf("tab:%s-passk-oss", metric_family),
  col.names = c("Model", paste0("k=", 1:5)),
  align = c("l", rep("c", 5)),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, out_tex)

```
# Build Success Rate
## Claude
```{r}

library(ggplot2)
library(readr)
library(scales)
library(dplyr)
library(stringr)
library(knitr)
library(kableExtra)

df <- read.csv("../analysis_results/all_models_summary.csv")

# ---- Set custom order here ----
custom_order <- c(
  "claude-sonnet-4_thinking0",
  "claude-sonnet-4_thinking8k",
  "claude-sonnet-4_thinking16k",
  "claude-sonnet-4_thinking24k"
)

exclude_models <- c(
  "o3",
  "gemini-2.5-pro",
  "qwen3-coder",
  "kimi-k2-0905",
  "gpt-4o",
  
  "gpt-5_reasoninglow",
  "gpt-5_reasoningmedium",
  "gpt-5_reasoninghigh",
  "gpt-oss-120b_reasoninglow",
  "gpt-oss-120b_reasoningmedium",
  "gpt-oss-120b_reasoninghigh"
)

# Rename mapping
model_names <- c(
  "gpt-5_reasoninglow"                = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"             = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"               = "GPT-5 (High Reasoning)",
  "o3"                                = "o3",
  "claude-sonnet-4_thinking0"         = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"        = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"       = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"       = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"                    = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"         = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium"      = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"        = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                       = "Qwen3 Coder",
  "kimi-k2-0905"                      = "Kimi K2 0905",
  "gpt-4o"                            = "GPT-4o"
)

# Filter and rename, applying custom order
df_filtered <- df %>%
  filter(!(model %in% exclude_models)) %>%
  mutate(model = recode(model, !!!model_names)) %>%
  mutate(model = factor(model, levels = recode(custom_order, !!!model_names))) %>%
  arrange(model)

# ---- Plot ----
p <- ggplot(df_filtered, aes(x = model, y = avg_build_success_rate, fill = model)) +
  geom_col() +
  
  geom_text(
    aes(label = scales::percent(avg_build_success_rate, accuracy=0.1)),
    vjust = -0.5,
    size = 3
  ) +
  labs(
    title = "Average Build Success Rate (k = 5)",
    subtitle = "Default model settings",
    x = "Model",
    y = "Average Build Success Rate (%)"
  ) +
  scale_y_continuous(
    labels = scales::percent,
    limits = c(0, 1)
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

p

# Export to pdf
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave("graphs/reasoning/reasoning_avg_build_success_rate_claude.pdf", plot = p, width = 6, height = 4, device = "pdf")

# ---- Table (LaTeX) ----
table_df <- df_filtered %>%
  mutate(
    Model = stringr::str_replace_all(as.character(model), "\n", "\\\\\n"),
    `Average Build Success Rate (\\%)` = sprintf("%.1f\\%%", avg_build_success_rate * 100)
  ) %>%
  select(Model, `Average Build Success Rate (\\%)`)

if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)

latex_tbl <- kable(
  table_df,
  format = "latex",
  booktabs = TRUE,
  caption = "Average build success rate (\\%) across $k=5$ generations.",
  label = "tab:avg-build-success",
  align = c("l","c"),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, "tables/reasoning/reasoning_avg_build_success_rate_claude.tex")


```

## GPT-5
```{r}

library(ggplot2)
library(readr)
library(scales)
library(dplyr)
library(stringr)
library(knitr)
library(kableExtra)

df <- read.csv("../analysis_results/all_models_summary.csv")

# ---- Set custom order here ----
custom_order <- c(
  "gpt-5_reasoninglow",
  "gpt-5_reasoningmedium",
  "gpt-5_reasoninghigh"
)

exclude_models <- c(
  "o3",
  "gemini-2.5-pro",
  "qwen3-coder",
  "kimi-k2-0905",
  "gpt-4o",
  
  "claude-sonnet-4_thinking0",
  "claude-sonnet-4_thinking8k",
  "claude-sonnet-4_thinking16k",
  "claude-sonnet-4_thinking24k",
  
  "gpt-oss-120b_reasoninglow",
  "gpt-oss-120b_reasoningmedium",
  "gpt-oss-120b_reasoninghigh"
)

# Rename mapping
model_names <- c(
  "gpt-5_reasoninglow"                = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"             = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"               = "GPT-5 (High Reasoning)",
  "o3"                                = "o3",
  "claude-sonnet-4_thinking0"         = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"        = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"       = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"       = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"                    = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"         = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium"      = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"        = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                       = "Qwen3 Coder",
  "kimi-k2-0905"                      = "Kimi K2 0905",
  "gpt-4o"                            = "GPT-4o"
)

# Filter and rename, applying custom order
df_filtered <- df %>%
  filter(!(model %in% exclude_models)) %>%
  mutate(model = recode(model, !!!model_names)) %>%
  mutate(model = factor(model, levels = recode(custom_order, !!!model_names))) %>%
  arrange(model)

# ---- Plot ----
p <- ggplot(df_filtered, aes(x = model, y = avg_build_success_rate, fill = model)) +
  geom_col() +
  
  geom_text(
    aes(label = scales::percent(avg_build_success_rate, accuracy=0.1)),
    vjust = -0.5,
    size = 3
  ) +
  labs(
    title = "Average Build Success Rate (k = 5)",
    subtitle = "Default model settings",
    x = "Model",
    y = "Average Build Success Rate (%)"
  ) +
  scale_y_continuous(
    labels = scales::percent,
    limits = c(0, 1)
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

p

# Export to pdf
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave("graphs/reasoning/reasoning_avg_build_success_rate_gpt5.pdf", plot = p, width = 6, height = 4, device = "pdf")

# ---- Table (LaTeX) ----
table_df <- df_filtered %>%
  mutate(
    Model = stringr::str_replace_all(as.character(model), "\n", "\\\\\n"),
    `Average Build Success Rate (\\%)` = sprintf("%.1f\\%%", avg_build_success_rate * 100)
  ) %>%
  select(Model, `Average Build Success Rate (\\%)`)

if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)

latex_tbl <- kable(
  table_df,
  format = "latex",
  booktabs = TRUE,
  caption = "Average build success rate (\\%) across $k=5$ generations.",
  label = "tab:avg-build-success",
  align = c("l","c"),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, "tables/reasoning/reasoning_avg_build_success_rate_gpt5.tex")


```

## gpt-oss-120b

```{r}

library(ggplot2)
library(readr)
library(scales)
library(dplyr)
library(stringr)
library(knitr)
library(kableExtra)

df <- read.csv("../analysis_results/all_models_summary.csv")

# ---- Set custom order here ----
custom_order <- c(
  "gpt-oss-120b_reasoninglow",
  "gpt-oss-120b_reasoningmedium",
  "gpt-oss-120b_reasoninghigh"
)

exclude_models <- c(
  "o3",
  "gemini-2.5-pro",
  "qwen3-coder",
  "kimi-k2-0905",
  "gpt-4o",
  
  "claude-sonnet-4_thinking0",
  "claude-sonnet-4_thinking8k",
  "claude-sonnet-4_thinking16k",
  "claude-sonnet-4_thinking24k",
  "gpt-5_reasoninglow",
  "gpt-5_reasoningmedium",
  "gpt-5_reasoninghigh"
  
  
)

# Rename mapping
model_names <- c(
  "gpt-5_reasoninglow"                = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"             = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"               = "GPT-5 (High Reasoning)",
  "o3"                                = "o3",
  "claude-sonnet-4_thinking0"         = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"        = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"       = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"       = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"                    = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"         = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium"      = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"        = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                       = "Qwen3 Coder",
  "kimi-k2-0905"                      = "Kimi K2 0905",
  "gpt-4o"                            = "GPT-4o"
)

# Filter and rename, applying custom order
df_filtered <- df %>%
  filter(!(model %in% exclude_models)) %>%
  mutate(model = recode(model, !!!model_names)) %>%
  mutate(model = factor(model, levels = recode(custom_order, !!!model_names))) %>%
  arrange(model)

# ---- Plot ----
p <- ggplot(df_filtered, aes(x = model, y = avg_build_success_rate, fill = model)) +
  geom_col() +
  
  geom_text(
    aes(label = scales::percent(avg_build_success_rate, accuracy=0.1)),
    vjust = -0.5,
    size = 3
  ) +
  labs(
    title = "Average Build Success Rate (k = 5)",
    subtitle = "Default model settings",
    x = "Model",
    y = "Average Build Success Rate (%)"
  ) +
  scale_y_continuous(
    labels = scales::percent,
    limits = c(0, 1)
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

p

# Export to pdf
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave("graphs/reasoning/reasoning_avg_build_success_rate_oss.pdf", plot = p, width = 6, height = 4, device = "pdf")

# ---- Table (LaTeX) ----
table_df <- df_filtered %>%
  mutate(
    Model = stringr::str_replace_all(as.character(model), "\n", "\\\\\n"),
    `Average Build Success Rate (\\%)` = sprintf("%.1f\\%%", avg_build_success_rate * 100)
  ) %>%
  select(Model, `Average Build Success Rate (\\%)`)

if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)

latex_tbl <- kable(
  table_df,
  format = "latex",
  booktabs = TRUE,
  caption = "Average build success rate (\\%) across $k=5$ generations.",
  label = "tab:avg-build-success",
  align = c("l","c"),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, "tables/reasoning/reasoning_avg_build_success_rate_oss.tex")


```

# Average Task Success Rate

As you add more reasoning, maybe the passing the tests goes up, and not the compilation failures going down.

# Funnel

## Claude

```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(scales)
library(stringr)

df <- read.csv("../analysis_results/all_models_summary.csv")

# ---- Set custom order here ----
custom_order <- c(
  "claude-sonnet-4_thinking0",
  "claude-sonnet-4_thinking8k",
  "claude-sonnet-4_thinking16k",
  "claude-sonnet-4_thinking24k"
)

exclude_models <- c(
  "o3",
  "gemini-2.5-pro",
  "qwen3-coder",
  "kimi-k2-0905",
  "gpt-4o",
  
  "gpt-5_reasoninglow",
  "gpt-5_reasoningmedium",
  "gpt-5_reasoninghigh",
  "gpt-oss-120b_reasoninglow",
  "gpt-oss-120b_reasoningmedium",
  "gpt-oss-120b_reasoninghigh"
)

# Rename mapping
model_names <- c(
  "gpt-5_reasoninglow"           = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"        = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"          = "GPT-5 (High Reasoning)",
  "o3"                           = "o3",
  "claude-sonnet-4_thinking0"    = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"   = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"  = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"  = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"               = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"    = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium" = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"   = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                  = "Qwen3 Coder",
  "kimi-k2-0905"                 = "Kimi K2 0905",
  "gpt-4o"                       = "GPT-4o"
)

# Filter, rename, and apply custom order
df_filtered <- df %>%
  filter(!(model %in% exclude_models)) %>%
  mutate(
    model = recode(model, !!!model_names),
    model = factor(model, levels = recode(custom_order, !!!model_names))
  ) %>%
  arrange(model)

# Per-generation funnel: GREEN bottom, ORANGE middle, RED top
df_funnel <- df_filtered %>%
  transmute(
    model,
    failed_build       = 1 - avg_build_success_rate,
    built_failed_test  = avg_build_success_rate - avg_test_success_rate,
    built_passed_test  = avg_test_success_rate
  ) %>%
  pivot_longer(
    cols = c(failed_build, built_failed_test, built_passed_test),
    names_to = "stage",
    values_to = "rate"
  ) %>%
  mutate(
    # enforce stack order: green (pass) → orange (failed tests) → red (failed build)
#    stage = factor(stage,
#                   levels = c("built_passed_test", "built_failed_test", "failed_build"))
    
    stage = factor(stage,
                   levels = c("failed_build", "built_failed_test", "built_passed_test"))
  )

# Optional: clearer labels
stage_labels <- c(
  "failed_build" = "Failed to compile",
  "built_failed_test" = "Compiled; tests failed",
  "built_passed_test" = "Compiled; tests passed"
)

# Keep your plot code, but update labels:
p <- ggplot(df_funnel, aes(x = model, y = rate, fill = stage)) +
  geom_col() +
  geom_text(
    aes(label = scales::percent(rate, accuracy = 0.01)),
    position = position_stack(vjust = 0.5),
    color = "black", size = 3.5
  ) +
  labs(
    title = "Compilation vs Test Outcomes",
    subtitle = "Share of generations (k = 5 per task)",
    x = "Model",
    y = "Percentage of Generations",
    fill = "Outcome"
  ) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(
    values = c(
      "failed_build" = "#e74c3c",
      "built_failed_test" = "#f39c12",
      "built_passed_test" = "#27ae60"
    ),
    labels = stage_labels
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p

# Export to pdf
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave("graphs/reasoning/reasoning_compilation_vs_success_claude.pdf", plot = p, width = 6, height = 4, device = "pdf")
# ---- Table (LaTeX): Compilation vs Test Outcomes ----
library(knitr)
library(kableExtra)

# Ensure output dir
if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)

# Wide table with columns in green → orange → red order
table_df <- df_funnel %>%
  mutate(
    Model = stringr::str_replace_all(as.character(model), "\n", "\\\\\n"),
    stage = factor(stage, levels = c("built_passed_test","built_failed_test","failed_build"))
  ) %>%
  select(Model, stage, rate) %>%
  tidyr::pivot_wider(names_from = stage, values_from = rate) %>%
  mutate(
    `Compiled; tests passed` = sprintf("%.1f\\%%", `built_passed_test` * 100),
    `Compiled; tests failed` = sprintf("%.1f\\%%", `built_failed_test` * 100),
    `Failed to compile`      = sprintf("%.1f\\%%", `failed_build` * 100)
  ) %>%
  select(Model, `Compiled; tests passed`, `Compiled; tests failed`, `Failed to compile`)

latex_tbl <- kable(
  table_df,
  format = "latex",
  booktabs = TRUE,
  caption = "Compilation vs. test outcomes per model (share of generations; green \\textrightarrow{} orange \\textrightarrow{} red).",
  label = "tab:compilation-vs-success",
  align = c("l","c","c","c"),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, "tables/reasoning/reasoning_compilation_vs_success_claude.tex")

```

## GPT-5

```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(scales)
library(stringr)

df <- read.csv("../analysis_results/all_models_summary.csv")

# ---- Set custom order here ----
custom_order <- c(
  
  "gpt-5_reasoninglow",
  "gpt-5_reasoningmedium",
  "gpt-5_reasoninghigh"
)

exclude_models <- c(
  "o3",
  "gemini-2.5-pro",
  "qwen3-coder",
  "kimi-k2-0905",
  "gpt-4o",
  
  "gpt-oss-120b_reasoninglow",
  "gpt-oss-120b_reasoningmedium",
  "gpt-oss-120b_reasoninghigh",
  
  "claude-sonnet-4_thinking0",
  "claude-sonnet-4_thinking8k",
  "claude-sonnet-4_thinking16k",
  "claude-sonnet-4_thinking24k"
)

# Rename mapping
model_names <- c(
  "gpt-5_reasoninglow"           = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"        = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"          = "GPT-5 (High Reasoning)",
  "o3"                           = "o3",
  "claude-sonnet-4_thinking0"    = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"   = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"  = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"  = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"               = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"    = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium" = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"   = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                  = "Qwen3 Coder",
  "kimi-k2-0905"                 = "Kimi K2 0905",
  "gpt-4o"                       = "GPT-4o"
)

# Filter, rename, and apply custom order
df_filtered <- df %>%
  filter(!(model %in% exclude_models)) %>%
  mutate(
    model = recode(model, !!!model_names),
    model = factor(model, levels = recode(custom_order, !!!model_names))
  ) %>%
  arrange(model)

# Per-generation funnel: GREEN bottom, ORANGE middle, RED top
df_funnel <- df_filtered %>%
  transmute(
    model,
    failed_build       = 1 - avg_build_success_rate,
    built_failed_test  = avg_build_success_rate - avg_test_success_rate,
    built_passed_test  = avg_test_success_rate
  ) %>%
  pivot_longer(
    cols = c(failed_build, built_failed_test, built_passed_test),
    names_to = "stage",
    values_to = "rate"
  ) %>%
  mutate(
    # enforce stack order: green (pass) → orange (failed tests) → red (failed build)
#    stage = factor(stage,
#                   levels = c("built_passed_test", "built_failed_test", "failed_build"))
    
    stage = factor(stage,
                   levels = c("failed_build", "built_failed_test", "built_passed_test"))
  )

# Optional: clearer labels
stage_labels <- c(
  "failed_build" = "Failed to compile",
  "built_failed_test" = "Compiled; tests failed",
  "built_passed_test" = "Compiled; tests passed"
)

# Keep your plot code, but update labels:
p <- ggplot(df_funnel, aes(x = model, y = rate, fill = stage)) +
  geom_col() +
  geom_text(
    aes(label = scales::percent(rate, accuracy = 0.01)),
    position = position_stack(vjust = 0.5),
    color = "black", size = 3.5
  ) +
  labs(
    title = "Compilation vs Test Outcomes",
    subtitle = "Share of generations (k = 5 per task)",
    x = "Model",
    y = "Percentage of Generations",
    fill = "Outcome"
  ) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(
    values = c(
      "failed_build" = "#e74c3c",
      "built_failed_test" = "#f39c12",
      "built_passed_test" = "#27ae60"
    ),
    labels = stage_labels
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p

# Export to pdf
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave("graphs/reasoning/reasoning_compilation_vs_success_gpt5.pdf", plot = p, width = 6, height = 4, device = "pdf")

# ---- Table (LaTeX): Compilation vs Test Outcomes ----
library(knitr)
library(kableExtra)

# Ensure output dir
if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)

# Wide table with columns in green → orange → red order
table_df <- df_funnel %>%
  mutate(
    Model = stringr::str_replace_all(as.character(model), "\n", "\\\\\n"),
    stage = factor(stage, levels = c("built_passed_test","built_failed_test","failed_build"))
  ) %>%
  select(Model, stage, rate) %>%
  tidyr::pivot_wider(names_from = stage, values_from = rate) %>%
  mutate(
    `Compiled; tests passed` = sprintf("%.1f\\%%", `built_passed_test` * 100),
    `Compiled; tests failed` = sprintf("%.1f\\%%", `built_failed_test` * 100),
    `Failed to compile`      = sprintf("%.1f\\%%", `failed_build` * 100)
  ) %>%
  select(Model, `Compiled; tests passed`, `Compiled; tests failed`, `Failed to compile`)

latex_tbl <- kable(
  table_df,
  format = "latex",
  booktabs = TRUE,
  caption = "Compilation vs. test outcomes per model (share of generations; green \\textrightarrow{} orange \\textrightarrow{} red).",
  label = "tab:compilation-vs-success",
  align = c("l","c","c","c"),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, "tables/reasoning/reasoning_compilation_vs_success_gpt5.tex")

```

## gpt-oss-120b
```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(scales)
library(stringr)

df <- read.csv("../analysis_results/all_models_summary.csv")

# ---- Set custom order here ----
custom_order <- c(
  
  "gpt-oss-120b_reasoninglow",
  "gpt-oss-120b_reasoningmedium",
  "gpt-oss-120b_reasoninghigh"
)

exclude_models <- c(
  "o3",
  "gemini-2.5-pro",
  "qwen3-coder",
  "kimi-k2-0905",
  "gpt-4o",
  
  
  "claude-sonnet-4_thinking0",
  "claude-sonnet-4_thinking8k",
  "claude-sonnet-4_thinking16k",
  "claude-sonnet-4_thinking24k",
  
  "gpt-5_reasoninglow",
  "gpt-5_reasoningmedium",
  "gpt-5_reasoninghigh"
)

# Rename mapping
model_names <- c(
  "gpt-5_reasoninglow"           = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"        = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"          = "GPT-5 (High Reasoning)",
  "o3"                           = "o3",
  "claude-sonnet-4_thinking0"    = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"   = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"  = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"  = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"               = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"    = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium" = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"   = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                  = "Qwen3 Coder",
  "kimi-k2-0905"                 = "Kimi K2 0905",
  "gpt-4o"                       = "GPT-4o"
)

# Filter, rename, and apply custom order
df_filtered <- df %>%
  filter(!(model %in% exclude_models)) %>%
  mutate(
    model = recode(model, !!!model_names),
    model = factor(model, levels = recode(custom_order, !!!model_names))
  ) %>%
  arrange(model)

# Per-generation funnel: GREEN bottom, ORANGE middle, RED top
df_funnel <- df_filtered %>%
  transmute(
    model,
    failed_build       = 1 - avg_build_success_rate,
    built_failed_test  = avg_build_success_rate - avg_test_success_rate,
    built_passed_test  = avg_test_success_rate
  ) %>%
  pivot_longer(
    cols = c(failed_build, built_failed_test, built_passed_test),
    names_to = "stage",
    values_to = "rate"
  ) %>%
  mutate(
    # enforce stack order: green (pass) → orange (failed tests) → red (failed build)
#    stage = factor(stage,
#                   levels = c("built_passed_test", "built_failed_test", "failed_build"))
    
    stage = factor(stage,
                   levels = c("failed_build", "built_failed_test", "built_passed_test"))
  )

# Optional: clearer labels
stage_labels <- c(
  "failed_build" = "Failed to compile",
  "built_failed_test" = "Compiled; tests failed",
  "built_passed_test" = "Compiled; tests passed"
)

# Keep your plot code, but update labels:
p <- ggplot(df_funnel, aes(x = model, y = rate, fill = stage)) +
  geom_col() +
  geom_text(
    aes(label = scales::percent(rate, accuracy = 0.01)),
    position = position_stack(vjust = 0.5),
    color = "black", size = 3.5
  ) +
  labs(
    title = "Compilation vs Test Outcomes",
    subtitle = "Share of generations (k = 5 per task)",
    x = "Model",
    y = "Percentage of Generations",
    fill = "Outcome"
  ) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(
    values = c(
      "failed_build" = "#e74c3c",
      "built_failed_test" = "#f39c12",
      "built_passed_test" = "#27ae60"
    ),
    labels = stage_labels
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p

# Export to pdf
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave("graphs/reasoning/reasoning_compilation_vs_success_oss.pdf", plot = p, width = 6, height = 4, device = "pdf")

# ---- Table (LaTeX): Compilation vs Test Outcomes ----
library(knitr)
library(kableExtra)

# Ensure output dir
if (!dir.exists("tables")) dir.create("tables", recursive = TRUE)

# Wide table with columns in green → orange → red order
table_df <- df_funnel %>%
  mutate(
    Model = stringr::str_replace_all(as.character(model), "\n", "\\\\\n"),
    stage = factor(stage, levels = c("built_passed_test","built_failed_test","failed_build"))
  ) %>%
  select(Model, stage, rate) %>%
  tidyr::pivot_wider(names_from = stage, values_from = rate) %>%
  mutate(
    `Compiled; tests passed` = sprintf("%.1f\\%%", `built_passed_test` * 100),
    `Compiled; tests failed` = sprintf("%.1f\\%%", `built_failed_test` * 100),
    `Failed to compile`      = sprintf("%.1f\\%%", `failed_build` * 100)
  ) %>%
  select(Model, `Compiled; tests passed`, `Compiled; tests failed`, `Failed to compile`)

latex_tbl <- kable(
  table_df,
  format = "latex",
  booktabs = TRUE,
  caption = "Compilation vs. test outcomes per model (share of generations; green \\textrightarrow{} orange \\textrightarrow{} red).",
  label = "tab:compilation-vs-success",
  align = c("l","c","c","c"),
  escape = FALSE
) %>%
  kable_styling(latex_options = c("hold_position"))

save_kable(latex_tbl, "tables/reasoning/reasoning_compilation_vs_success_oss.tex")

```
```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(tidyr)
library(scales)
library(stringr)

df <- read.csv("../analysis_results/all_models_summary.csv")

# ---- Set custom order here ----
custom_order <- c(
  
  "gpt-5_reasoninglow",
  "gpt-5_reasoningmedium",
  "gpt-5_reasoninghigh"
)

exclude_models <- c(
  "o3",
  "gemini-2.5-pro",
  "qwen3-coder",
  "kimi-k2-0905",
  "gpt-4o",
  
  "gpt-oss-120b_reasoninglow",
  "gpt-oss-120b_reasoningmedium",
  "gpt-oss-120b_reasoninghigh",
  
  "claude-sonnet-4_thinking0",
  "claude-sonnet-4_thinking8k",
  "claude-sonnet-4_thinking16k",
  "claude-sonnet-4_thinking24k"
)

# Rename mapping
model_names <- c(
  "gpt-5_reasoninglow"           = "GPT-5 (Low Reasoning)",
  "gpt-5_reasoningmedium"        = "GPT-5 (Medium Reasoning)",
  "gpt-5_reasoninghigh"          = "GPT-5 (High Reasoning)",
  "o3"                           = "o3",
  "claude-sonnet-4_thinking0"    = "Claude Sonnet 4\n(0k Thinking Tokens)",
  "claude-sonnet-4_thinking8k"   = "Claude Sonnet 4\n(8k Thinking Tokens)",
  "claude-sonnet-4_thinking16k"  = "Claude Sonnet 4\n(16k Thinking Tokens)",
  "claude-sonnet-4_thinking24k"  = "Claude Sonnet 4\n(24k Thinking Tokens)",
  "gemini-2.5-pro"               = "Gemini 2.5 Pro",
  "gpt-oss-120b_reasoninglow"    = "gpt-oss-120b (Low Reasoning)",
  "gpt-oss-120b_reasoningmedium" = "gpt-oss-120b (Medium Reasoning)",
  "gpt-oss-120b_reasoninghigh"   = "gpt-oss-120b (High Reasoning)",
  "qwen3-coder"                  = "Qwen3 Coder",
  "kimi-k2-0905"                 = "Kimi K2 0905",
  "gpt-4o"                       = "GPT-4o"
)

# Filter, rename, and apply custom order
df_filtered <- df %>%
  filter(!(model %in% exclude_models)) %>%
  mutate(
    model = recode(model, !!!model_names),
    model = factor(model, levels = recode(custom_order, !!!model_names))
  ) %>%
  arrange(model)

# Per-generation funnel: GREEN bottom, ORANGE middle, RED top
df_funnel <- df_filtered %>%
  transmute(
    model,
    failed_build       = 1 - avg_build_success_rate,
    built_failed_test  = avg_build_success_rate - avg_test_success_rate,
    built_passed_test  = avg_test_success_rate
  ) %>%
  pivot_longer(
    cols = c(failed_build, built_failed_test, built_passed_test),
    names_to = "stage",
    values_to = "rate"
  ) %>%
  mutate(
    # enforce stack order: green (pass) → orange (failed tests) → red (failed build)
#    stage = factor(stage,
#                   levels = c("built_passed_test", "built_failed_test", "failed_build"))
    
    stage = factor(stage,
                   levels = c("failed_build", "built_failed_test", "built_passed_test"))
  )

# Optional: clearer labels
stage_labels <- c(
  "failed_build" = "Failed to compile",
  "built_failed_test" = "Compiled; tests failed",
  "built_passed_test" = "Compiled; tests passed"
)

# Keep your plot code, but update labels:
p <- ggplot(df_funnel, aes(x = model, y = rate, fill = stage)) +
  geom_col() +
  geom_text(
    aes(label = scales::percent(rate, accuracy = 1)),
    position = position_stack(vjust = 0.5),
    color = "black", size = 3.5
  ) +
  labs(
    title = "Compilation vs Test Outcomes",
    subtitle = "Share of generations (k = 5 per task)",
    x = "Model",
    y = "Percentage of Generations",
    fill = "Outcome"
  ) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(
    values = c(
      "failed_build" = "#e74c3c",
      "built_failed_test" = "#f39c12",
      "built_passed_test" = "#27ae60"
    ),
    labels = stage_labels
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p

# Export to pdf
if (!dir.exists("graphs")) dir.create("graphs", recursive = TRUE)
ggsave("graphs/reasoning/reasoning_compilation_vs_success_gpt5.pdf", plot = p, width = 6, height = 4, device = "pdf")
```

